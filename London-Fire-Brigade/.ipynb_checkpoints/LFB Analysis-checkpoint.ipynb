{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6de422b4",
   "metadata": {},
   "source": [
    "# London Fire Incidents Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7d355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d26028f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4583b",
   "metadata": {},
   "source": [
    "### Downloading and loadng the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7428026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Memory Used : 2091.97 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentNumber</th>\n",
       "      <th>DateOfCall</th>\n",
       "      <th>CalYear</th>\n",
       "      <th>TimeOfCall</th>\n",
       "      <th>HourOfCall</th>\n",
       "      <th>IncidentGroup</th>\n",
       "      <th>StopCodeDescription</th>\n",
       "      <th>SpecialServiceType</th>\n",
       "      <th>PropertyCategory</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>...</th>\n",
       "      <th>FirstPumpArriving_AttendanceTime</th>\n",
       "      <th>FirstPumpArriving_DeployedFromStation</th>\n",
       "      <th>SecondPumpArriving_AttendanceTime</th>\n",
       "      <th>SecondPumpArriving_DeployedFromStation</th>\n",
       "      <th>NumStationsWithPumpsAttending</th>\n",
       "      <th>NumPumpsAttending</th>\n",
       "      <th>PumpCount</th>\n",
       "      <th>PumpHoursRoundUp</th>\n",
       "      <th>Notional Cost (£)</th>\n",
       "      <th>NumCalls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235138081</td>\n",
       "      <td>01 Jan 2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>00:00:37</td>\n",
       "      <td>0</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>RTC</td>\n",
       "      <td>Road Vehicle</td>\n",
       "      <td>Car</td>\n",
       "      <td>...</td>\n",
       "      <td>319.0</td>\n",
       "      <td>Battersea</td>\n",
       "      <td>342.0</td>\n",
       "      <td>Clapham</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1091</td>\n",
       "      <td>01 Jan 2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>00:00:46</td>\n",
       "      <td>0</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>Assist other agencies</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Lake/pond/reservoir</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2091</td>\n",
       "      <td>01 Jan 2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Secondary Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Road surface/pavement</td>\n",
       "      <td>...</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3091</td>\n",
       "      <td>01 Jan 2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>00:04:27</td>\n",
       "      <td>0</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Secondary Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Domestic garden (vegetation not equipment)</td>\n",
       "      <td>...</td>\n",
       "      <td>210.0</td>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5091</td>\n",
       "      <td>01 Jan 2009</td>\n",
       "      <td>2009</td>\n",
       "      <td>00:05:39</td>\n",
       "      <td>0</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Secondary Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Cycle path/public footpath/bridleway</td>\n",
       "      <td>...</td>\n",
       "      <td>233.0</td>\n",
       "      <td>Holloway</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Holloway</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  IncidentNumber   DateOfCall  CalYear TimeOfCall  HourOfCall  \\\n",
       "0      235138081  01 Jan 2009     2009   00:00:37           0   \n",
       "1           1091  01 Jan 2009     2009   00:00:46           0   \n",
       "2           2091  01 Jan 2009     2009   00:03:00           0   \n",
       "3           3091  01 Jan 2009     2009   00:04:27           0   \n",
       "4           5091  01 Jan 2009     2009   00:05:39           0   \n",
       "\n",
       "     IncidentGroup StopCodeDescription     SpecialServiceType  \\\n",
       "0  Special Service     Special Service                    RTC   \n",
       "1  Special Service     Special Service  Assist other agencies   \n",
       "2             Fire      Secondary Fire                    NaN   \n",
       "3             Fire      Secondary Fire                    NaN   \n",
       "4             Fire      Secondary Fire                    NaN   \n",
       "\n",
       "  PropertyCategory                                 PropertyType  ...  \\\n",
       "0     Road Vehicle                                         Car   ...   \n",
       "1          Outdoor                         Lake/pond/reservoir   ...   \n",
       "2          Outdoor                       Road surface/pavement   ...   \n",
       "3          Outdoor  Domestic garden (vegetation not equipment)   ...   \n",
       "4          Outdoor        Cycle path/public footpath/bridleway   ...   \n",
       "\n",
       "  FirstPumpArriving_AttendanceTime FirstPumpArriving_DeployedFromStation  \\\n",
       "0                            319.0                             Battersea   \n",
       "1                              NaN                                   NaN   \n",
       "2                            308.0                              Edmonton   \n",
       "3                            210.0                            Hillingdon   \n",
       "4                            233.0                              Holloway   \n",
       "\n",
       "  SecondPumpArriving_AttendanceTime  SecondPumpArriving_DeployedFromStation  \\\n",
       "0                             342.0                                 Clapham   \n",
       "1                               NaN                                     NaN   \n",
       "2                               NaN                                     NaN   \n",
       "3                               NaN                                     NaN   \n",
       "4                             250.0                                Holloway   \n",
       "\n",
       "   NumStationsWithPumpsAttending NumPumpsAttending PumpCount PumpHoursRoundUp  \\\n",
       "0                            2.0               2.0       2.0              1.0   \n",
       "1                            NaN               NaN       NaN              NaN   \n",
       "2                            1.0               1.0       1.0              1.0   \n",
       "3                            1.0               1.0       1.0              1.0   \n",
       "4                            1.0               2.0       2.0              1.0   \n",
       "\n",
       "  Notional Cost (£) NumCalls  \n",
       "0             255.0      1.0  \n",
       "1               NaN      1.0  \n",
       "2             255.0      2.0  \n",
       "3             255.0      2.0  \n",
       "4             255.0      1.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "# import data_download\n",
    "\n",
    "data_dir = \"LFB-data\"\n",
    "# LFB_data = pd.read_csv(os.path.join(data_dir, \"LFB Incident data - Datastore - with notional cost and UPRN from January 2009.csv\"))\n",
    "LFB_data = pd.read_csv(os.path.join(data_dir, \"lfb_incident.csv\"))\n",
    "\n",
    "# Total memory used\n",
    "print(f'Total Memory Used : {round(LFB_data.memory_usage(deep=True).sum()/(1024*1024), 2)} MB')\n",
    "LFB_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd162c7e",
   "metadata": {},
   "source": [
    "# %pip install plotly\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.density_mapbox(LFB_data, lat='Latitude', lon='Longitude', radius=10,\n",
    "                       center = dict(lat = 50, lon= 0.5), zoom=3,\n",
    "                       mapbox_style='stamen-terrain')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63987faa",
   "metadata": {},
   "source": [
    "### Primary Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1224ad45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465060, 39)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFB_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2c41d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1465060 entries, 0 to 1465059\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                  Non-Null Count    Dtype  \n",
      "---  ------                                  --------------    -----  \n",
      " 0   IncidentNumber                          1465060 non-null  object \n",
      " 1   DateOfCall                              1465060 non-null  object \n",
      " 2   CalYear                                 1465060 non-null  int64  \n",
      " 3   TimeOfCall                              1465060 non-null  object \n",
      " 4   HourOfCall                              1465060 non-null  int64  \n",
      " 5   IncidentGroup                           1465060 non-null  object \n",
      " 6   StopCodeDescription                     1465060 non-null  object \n",
      " 7   SpecialServiceType                      459204 non-null   object \n",
      " 8   PropertyCategory                        1465060 non-null  object \n",
      " 9   PropertyType                            1465060 non-null  object \n",
      " 10  AddressQualifier                        1465060 non-null  object \n",
      " 11  Postcode_full                           758683 non-null   object \n",
      " 12  Postcode_district                       1465060 non-null  object \n",
      " 13  UPRN                                    1323727 non-null  float64\n",
      " 14  USRN                                    1302189 non-null  float64\n",
      " 15  IncGeo_BoroughCode                      1465060 non-null  object \n",
      " 16  IncGeo_BoroughName                      1465060 non-null  object \n",
      " 17  ProperCase                              1465060 non-null  object \n",
      " 18  IncGeo_WardCode                         1465056 non-null  object \n",
      " 19  IncGeo_WardName                         1465056 non-null  object \n",
      " 20  IncGeo_WardNameNew                      1465056 non-null  object \n",
      " 21  Easting_m                               758683 non-null   float64\n",
      " 22  Northing_m                              758683 non-null   float64\n",
      " 23  Easting_rounded                         1465060 non-null  int64  \n",
      " 24  Northing_rounded                        1465060 non-null  int64  \n",
      " 25  Latitude                                758683 non-null   float64\n",
      " 26  Longitude                               758683 non-null   float64\n",
      " 27  FRS                                     1465060 non-null  object \n",
      " 28  IncidentStationGround                   1465059 non-null  object \n",
      " 29  FirstPumpArriving_AttendanceTime        1345308 non-null  float64\n",
      " 30  FirstPumpArriving_DeployedFromStation   1345296 non-null  object \n",
      " 31  SecondPumpArriving_AttendanceTime       525497 non-null   float64\n",
      " 32  SecondPumpArriving_DeployedFromStation  525490 non-null   object \n",
      " 33  NumStationsWithPumpsAttending           1454279 non-null  float64\n",
      " 34  NumPumpsAttending                       1454279 non-null  float64\n",
      " 35  PumpCount                               1456878 non-null  float64\n",
      " 36  PumpHoursRoundUp                        1456617 non-null  float64\n",
      " 37  Notional Cost (£)                       1456617 non-null  float64\n",
      " 38  NumCalls                                1463216 non-null  float64\n",
      "dtypes: float64(14), int64(4), object(21)\n",
      "memory usage: 435.9+ MB\n"
     ]
    }
   ],
   "source": [
    "LFB_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3014003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see if the data has missing values.\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "cols = LFB_data.columns[:]\n",
    "colours = ['#000099', '#ffff00'] # specify the colours - yellow is missing. blue is not missing.\n",
    "sns.heatmap(LFB_data[cols].isnull(), cmap=sns.color_palette(colours))\n",
    "print(\"Yellow - Missing Values\\nBlue - Non Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183fd70a",
   "metadata": {},
   "source": [
    "We can see that there are missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65e825",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50213c9",
   "metadata": {},
   "source": [
    "### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf04243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numeric columns\n",
    "df_numeric = LFB_data.select_dtypes(include=[np.number])\n",
    "\n",
    "print(\"Numeric data shape : \",df_numeric.shape)\n",
    "df_numeric.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.describe().T.apply(lambda s: s.apply('{0:.2f}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37f8a2",
   "metadata": {},
   "source": [
    "We can tell from the data above that there are outliers in the numeric data.\n",
    "For instance, there are values that have a very huge diffrence between the 75th percentile and maximum value\n",
    "\n",
    "#### Numerical data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0087298",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize= (20,50))\n",
    "\n",
    "for i in range(len(df_numeric.columns)):\n",
    "    column = df_numeric.columns[i]\n",
    "    sub = fig.add_subplot(9,3, i+1)\n",
    "    chart = sns.boxplot(data=df_numeric, y=column, x = LFB_data[\"IncidentGroup\"])\n",
    "    chart.set_title(column + \" by incident group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a768b",
   "metadata": {},
   "source": [
    "#### Missing values on Numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4441ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any missing values\n",
    "print(\"Number of cols with Missing Vals: \",df_numeric.isna().any().sum())\n",
    "display(df_numeric.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc3728c",
   "metadata": {},
   "source": [
    "<h6>We need to fix the missing values to cluster around the mean value<br>We will consider randomizing the missing values between 30% and 70%</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998b4f4",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in df_numeric[['UPRN', 'USRN', 'Easting_m', 'Northing_m','Easting_rounded', 'Northing_rounded',\n",
    "                    'FirstPumpArriving_AttendanceTime','SecondPumpArriving_AttendanceTime',\n",
    "                    'NumStationsWithPumpsAttending', 'NumPumpsAttending', 'PumpCount',\n",
    "                    'PumpHoursRoundUp', 'Notional Cost (£)', 'NumCalls']]:\n",
    "    df_numeric.fillna(0, inplace=True)\n",
    "    # Set 30 and 70th percentile and round off to 2\n",
    "    rand_30_70 = random.uniform(round(np.percentile(df_numeric[i],30),2), round(np.percentile(df_numeric[i],70),2)) \n",
    "    for j in i:\n",
    "        if j == 0:\n",
    "            df_numeric.replace(to_replace=0, value=rand_30_70, inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c13c1",
   "metadata": {},
   "source": [
    "#### Outliers in numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b10104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_numeric.columns:\n",
    "    df_numeric.fillna(df_numeric[i].mode()[0], inplace = True)\n",
    "    highest_val = df_numeric[i].mean() + 3*df_numeric[i].std()\n",
    "    lowest_val = df_numeric[i].mean() - 3*df_numeric[i].std()\n",
    "    print(f\"Range for {i} : \", round(lowest_val,2), \" to \",round(highest_val,2))\n",
    "    \n",
    "#     Trimming the outliers\n",
    "    df_numeric[i]= np.where(df_numeric[i]>highest_val, highest_val,\n",
    "                           np.where(df_numeric[i]<lowest_val, lowest_val,\n",
    "                                   df_numeric[i]))\n",
    "#     (df_numeric[i]>=lowest_val)&(df_numeric[i]<=highest_val)\n",
    "\n",
    "print( \"\\n\",\"*\"*120)\n",
    "df_numeric.describe().T.apply(lambda s: s.apply('{0:.2f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d20c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183ec33",
   "metadata": {},
   "source": [
    "### Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical = LFB_data.select_dtypes(exclude=[np.number])\n",
    "print(df_categorical.shape)\n",
    "print( \"\\n\",\"-\"*120)\n",
    "df_categorical.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_categorical['IncGeo_WardName'] == df_categorical['IncGeo_WardNameNew'])\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the incidentnumber, postcode_full,  column since we really dont need it\n",
    "df_categorical.drop(['IncidentNumber', 'Postcode_full', 'IncGeo_WardNameNew'], axis = 1, inplace=True)\n",
    "\n",
    "# Create a new column from the DateOfCall column.\n",
    "df_categorical['MonthOfCall'] = df_categorical['DateOfCall'].apply(lambda x: x.split(\" \")[1])\n",
    "df_categorical['YearOfCall'] = df_categorical['DateOfCall'].apply(lambda x: x.split(\" \")[2])\n",
    "df_categorical.drop('DateOfCall', axis=1, inplace = True)\n",
    "\n",
    "\n",
    "# Create a new column from the DateOfCall column.\n",
    "df_categorical['HourOfCall'] = df_categorical['TimeOfCall'].apply(lambda x: x.split(\":\")[0])\n",
    "df_categorical.drop('TimeOfCall', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b90be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show new dataframe\n",
    "\n",
    "df_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41afb77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique values for each categorcal variable\n",
    "\n",
    "df_categorical.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb2107e",
   "metadata": {},
   "source": [
    "### Joining dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55231b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df_numeric, df_categorical], axis = 1)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9cd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae0588",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.get_dummies(final_df)\n",
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a29535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bb0c212",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb893c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "rand_num=random.sample(range(len(final_df)), 100000)\n",
    "rand_num[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621949fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = final_df.iloc[rand_num]\n",
    "working_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37b3fffb",
   "metadata": {},
   "source": [
    "for count, i in enumerate(working_df.columns):\n",
    "    print(count, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9102439",
   "metadata": {},
   "source": [
    "## T-Stochastic Neighbor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e00612",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import scipy\n",
    "import time\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import stats\n",
    "# A=scipy.spatial.distance.pdist(working_df, metric='euclidean')\n",
    "# kendTSNE=[]\n",
    "\n",
    "start_time = time.time()\n",
    "tsne = TSNE(n_components = 2, verbose=1, learning_rate=200, n_iter=500)\n",
    "tsne_result = tsne.fit_transform(X=working_df)\n",
    "end_time = time.time()\n",
    "print(\"Learning completed in {} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6cd2986",
   "metadata": {},
   "source": [
    "for k in len(working_df):\n",
    "    embed = TSNE(n_jobs=8, perplexity=k,n_components=2)\n",
    "    X_tsne = embed.fit_transform(working_df)\n",
    "    B=scipy.spatial.distance.pdist(X_tsne, metric='euclidean')\n",
    "    kendTSNE.append(scipy.stats.kendalltau(A, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81418556",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame({\"t-SNE 1\":tsne_result[:,0], \"t-SNE 2\":tsne_result[:,1]})\n",
    "tsne_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab377ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the tsne data\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(15,10))\n",
    "sns.scatterplot(x = 't-SNE 1', y= 't-SNE 2', data = tsne_df, ax = ax, s=20, palette = 'dark')\n",
    "sns.color_palette(\"hls\", 10)\n",
    "lim = (tsne_df.min()-5, tsne_df.max()+5)\n",
    "ax.set_title('t-SNE Visualization of Incident Group', fontsize = 16, weight = 'bold')\n",
    "ax.legend(bbox_to_anchor = (1,1), loc =2, borderaxespad = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fff91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36e40502",
   "metadata": {},
   "source": [
    "## Same Degree Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94520a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils._openmp_helpers import _openmp_effective_n_threads\n",
    "from sklearn.utils.validation import check_non_negative\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "MACHINE_EPSILON = np.finfo(np.double).eps"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d8c78cf",
   "metadata": {},
   "source": [
    "def _joint_probabilities(X, degrees_of_freedom):\n",
    "    dist = pdist(X, \"sqeuclidean\")\n",
    "    dist += 1.\n",
    "    dist **= (-degrees_of_freedom)\n",
    "    P= np.maximum(dist / ( np.sum(dist)), MACHINE_EPSILON)\n",
    "    return P\n",
    "\n",
    "\n",
    "def _kl_divergence(params, P, degrees_of_freedom, n_samples, n_components,\n",
    "                  skip_num_points=0, compute_error=True):\n",
    "\n",
    "    X_embedded = params.reshape(n_samples, n_components)\n",
    "    dist = pdist(X_embedded, \"sqeuclidean\")\n",
    "    Dist=dist+ 1.\n",
    "    dist= Dist**(-degrees_of_freedom)\n",
    "    Q = np.maximum(dist / (np.sum(dist)), MACHINE_EPSILON)\n",
    "    dist1=Dist**(-1)\n",
    "    kl_divergence =np.dot(P, np.log(np.maximum(P, MACHINE_EPSILON) / Q))\n",
    "    grad = np.ndarray((n_samples, n_components), dtype=params.dtype)\n",
    "    PQd = squareform((P - Q) * dist1)\n",
    "    for i in range(skip_num_points, n_samples):\n",
    "        grad[i] = np.dot(np.ravel(PQd[i]),\n",
    "                        X_embedded[i] - X_embedded)\n",
    "    grad = grad.ravel()\n",
    "    c = 2*(degrees_of_freedom + 1.0) \n",
    "    grad *= c\n",
    "\n",
    "    return kl_divergence, grad\n",
    "\n",
    "def _gradient_descent(objective, p0, it, n_iter,\n",
    "                     n_iter_check=1, n_iter_without_progress=300,\n",
    "                     momentum=0.5, learning_rate=7, min_gain=0.01,\n",
    "                     min_grad_norm=1e-7, verbose=0, args=None, kwargs=None):\n",
    "    if args is None:\n",
    "        args = []\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "\n",
    "    p = p0.copy().ravel()\n",
    "    update = np.zeros_like(p)\n",
    "    gains = np.ones_like(p)\n",
    "    error = np.finfo(np.float).max\n",
    "    best_error = np.finfo(np.float).max\n",
    "    best_iter = i = it\n",
    "\n",
    "    tic = time()\n",
    "    for i in range(it, n_iter):\n",
    "        check_convergence = (i + 1) % n_iter_check == 0\n",
    "       \n",
    "        kwargs['compute_error'] = check_convergence or i == n_iter - 1\n",
    "\n",
    "        error, grad = objective(p, *args, **kwargs)\n",
    "        grad_norm = linalg.norm(grad)\n",
    "\n",
    "        inc = update * grad < 0.0\n",
    "        dec = np.invert(inc)\n",
    "        gains[inc] += 0.2\n",
    "        gains[dec] *= 0.8\n",
    "        np.clip(gains, min_gain, np.inf, out=gains)\n",
    "        grad *= gains\n",
    "        update = momentum * update - learning_rate * grad\n",
    "        p += update\n",
    "\n",
    "        if check_convergence:\n",
    "            toc = time()\n",
    "            duration = toc - tic\n",
    "            tic = toc\n",
    "\n",
    "            if verbose >= 2:\n",
    "                print(\"[t-SNE] Iteration %d: error = %.7f,\"\n",
    "                     \" gradient norm = %.7f\"\n",
    "                     \" (%s iterations in %0.3fs)\"\n",
    "                     % (i + 1, error, grad_norm, n_iter_check, duration))\n",
    "\n",
    "            if error < best_error:\n",
    "                best_error = error\n",
    "                best_iter = i\n",
    "            elif i - best_iter > n_iter_without_progress:\n",
    "                if verbose >= 2:\n",
    "                    print(\"[t-SNE] Iteration %d: did not make any progress \"\n",
    "                         \"during the last %d episodes. Finished.\"\n",
    "                         % (i + 1, n_iter_without_progress))\n",
    "                break\n",
    "            if grad_norm <= min_grad_norm:\n",
    "                if verbose >= 2:\n",
    "                    print(\"[t-SNE] Iteration %d: gradient norm %f. Finished.\"\n",
    "                         % (i + 1, grad_norm))\n",
    "                break\n",
    "\n",
    "    return p, error, i\n",
    "\n",
    "\n",
    "class SDD(BaseEstimator):\n",
    "   \n",
    "   \n",
    "    _EXPLORATION_N_ITER = 300\n",
    "    _N_ITER_CHECK =50\n",
    "    def _fit(self, X, degrees_of_freedom, skip_num_points=0):\n",
    "        random_state=None\n",
    "        n_samples=X.shape[0]\n",
    "        P = _joint_probabilities(X,degrees_of_freedom)\n",
    "\n",
    "        random_state = check_random_state(random_state)\n",
    "\n",
    "        X_embedded = 1e-4 * random_state.randn(\n",
    "               n_samples, 2).astype(np.float32)\n",
    "\n",
    "        return self._tsne(P, degrees_of_freedom, n_samples,X_embedded=X_embedded,skip_num_points=skip_num_points)\n",
    "    def _tsne(self, P, degrees_of_freedom, n_samples, X_embedded, skip_num_points=0):\n",
    "        \"\"\"Runs t-SNE.\"\"\"\n",
    "        params = X_embedded.ravel()\n",
    "\n",
    "        opt_args = {\n",
    "           \"it\": 0,\n",
    "           \"n_iter_check\": 50,\n",
    "           \"min_grad_norm\": 1e-7,\n",
    "           \"learning_rate\": 7,\n",
    "           \"verbose\": 0,\n",
    "           \"kwargs\": dict(skip_num_points=skip_num_points),\n",
    "           \"args\": [P, degrees_of_freedom, n_samples, 2],\n",
    "           \"n_iter_without_progress\": 300,\n",
    "           \"n_iter\": 300,\n",
    "           \"momentum\": 0.8,\n",
    "       }\n",
    "        obj_func = _kl_divergence\n",
    "\n",
    "        params, kl_divergence, it = _gradient_descent(obj_func, params,\n",
    "                                                     **opt_args)\n",
    "        P /= 1\n",
    "        remaining =2000 - 300\n",
    "        if it < 300 or remaining > 0:\n",
    "            opt_args['n_iter'] = 2000\n",
    "            opt_args['it'] = it + 1\n",
    "            opt_args['momentum'] = 0.8\n",
    "            opt_args['n_iter_without_progress'] = 300\n",
    "            params, kl_divergence, it = _gradient_descent(obj_func, params,\n",
    "                                                         **opt_args)\n",
    "\n",
    "        self.n_iter_ = it\n",
    "        X_embedded = params.reshape(n_samples, 2)\n",
    "        self.kl_divergence_ = kl_divergence\n",
    "\n",
    "        return X_embedded\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "04b2e48da8715d0e03ed003238e610aa18fc3abec3b418b1e66df75f2c0e936e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
